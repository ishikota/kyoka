#!/usr/local/bin/python

# Resolve path configucation
import os
import sys
import argparse

root = os.path.join(os.path.dirname(__file__), "../"*3)
src_path = os.path.join(root, "kyoka")
sample_path = os.path.join(root, "sample")
sys.path.append(root)
sys.path.append(src_path)
sys.path.append(sample_path)

import logging as log
log.basicConfig(format='[%(levelname)s] %(message)s', level=log.INFO)

from kyoka.algorithm.montecarlo.montecarlo import MonteCarlo
from kyoka.algorithm.td_learning.sarsa import Sarsa
from kyoka.algorithm.td_learning.q_learning import QLearning
from kyoka.algorithm.td_learning.sarsa_lambda import SarsaLambda
from kyoka.algorithm.td_learning.q_lambda import QLambda

from kyoka.policy.epsilon_greedy_policy import EpsilonGreedyPolicy
from kyoka.finish_rule.watch_iteration_count import WatchIterationCount
from kyoka.finish_rule.manual_interruption import ManualInterruption

from sample.ticktacktoe.ticktacktoe_domain import TickTackToeDomain
from sample.ticktacktoe.ticktacktoe_table_value_function import TickTackToeTableValueFunction
from sample.ticktacktoe.ticktacktoe_helper import TickTackToeHelper

parser = argparse.ArgumentParser(description="Specify RL algorithm to use")
parser.add_argument("--algo", required=True, help='pass "montecarlo" or "sarsa" or "qlearning" or "sarsalambda" or "qlambda"')
parser.add_argument("--firstplayer", required=False, default="y", help='pass "yes" if you want to train first player (default is "yes")')
args = parser.parse_args()
algo = args.algo
is_first_player = True if args.firstplayer.lower() in ["yes", "y"] else False
if algo not in ["montecarlo", "sarsa", "qlearning", "sarsalambda", "qlambda"]:
  raise ValueError("unknown algorithm [%s] passed." % algo)

which_player = "firstplayer" if is_first_player else "secondplayer"
VALUE_FUNC_DIR_PATH = "%s_%s_ticktacktoe_value_function_data" % (algo, which_player)
VALUE_FUNC_SAVE_PATH = os.path.join(os.path.dirname(__file__), VALUE_FUNC_DIR_PATH)
INTERRUPTION_MONITOR_FILE_PATH = os.path.join(os.path.dirname(__file__), "interruption_order.txt")

RL_algo = {
    "montecarlo": lambda : MonteCarlo(),
    "sarsa": lambda : Sarsa(),
    "qlearning": lambda :QLearning(),
    "sarsalambda": lambda :SarsaLambda(),
    "qlambda": lambda :QLambda()
}[algo]()

domain = TickTackToeDomain(is_first_player=is_first_player)
value_func = TickTackToeTableValueFunction()


policy = EpsilonGreedyPolicy(eps=0.7)
manual_interruption = ManualInterruption(monitor_file_path=INTERRUPTION_MONITOR_FILE_PATH, log_interval=10000)
finish_rules = [manual_interruption]

RL_algo.setUp(domain, policy, value_func)
if os.path.exists(VALUE_FUNC_SAVE_PATH):
  log.info("loading value function from %s" % VALUE_FUNC_SAVE_PATH)
  RL_algo.load(VALUE_FUNC_SAVE_PATH)
  log.info("finished loading value function")

log.info("started GPI iteration...")
RL_algo.run_gpi(10, finish_rules=finish_rules)

log.info("saving value function into %s" % VALUE_FUNC_SAVE_PATH)
if not os.path.exists(os.path.join(os.path.dirname(__file__), VALUE_FUNC_DIR_PATH)):
  os.mkdir(os.path.join(os.path.dirname(__file__), VALUE_FUNC_DIR_PATH))
RL_algo.save(VALUE_FUNC_SAVE_PATH)
log.info("finished saving value function")

