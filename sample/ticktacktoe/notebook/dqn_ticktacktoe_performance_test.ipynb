{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for Performance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "root = \"../\"*3\n",
    "src_path = os.path.join(root, \"kyoka\")\n",
    "sample_path = os.path.join(root, \"sample\")\n",
    "sys.path.append(root)\n",
    "sys.path.append(src_path)\n",
    "sys.path.append(sample_path)\n",
    "\n",
    "import logging as log\n",
    "log.basicConfig(format='[%(levelname)s] %(message)s', level=log.INFO)\n",
    "\n",
    "from kyoka.algorithm.montecarlo.montecarlo import MonteCarlo\n",
    "from kyoka.algorithm.td_learning.sarsa import Sarsa\n",
    "from kyoka.algorithm.td_learning.q_learning import QLearning\n",
    "from kyoka.algorithm.td_learning.sarsa_lambda import SarsaLambda\n",
    "from kyoka.algorithm.td_learning.q_lambda import QLambda\n",
    "\n",
    "from kyoka.policy.greedy_policy import GreedyPolicy\n",
    "from kyoka.policy.epsilon_greedy_policy import EpsilonGreedyPolicy\n",
    "from kyoka.finish_rule.watch_iteration_count import WatchIterationCount\n",
    "\n",
    "from sample.ticktacktoe.ticktacktoe_domain import TickTackToeDomain\n",
    "from sample.ticktacktoe.ticktacktoe_helper import TickTackToeHelper\n",
    "from sample.ticktacktoe.ticktacktoe_manual_policy import TickTackToeManualPolicy\n",
    "from sample.ticktacktoe.ticktacktoe_perfect_policy import TickTackToePerfectPolicy\n",
    "from sample.ticktacktoe.ticktacktoe_performance_logger import TickTackToePerformanceLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Const for Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOG_INTERVAL = 1000\n",
    "TEST_GAME_COUNT = 10\n",
    "IS_FIRST_PLAYER = True\n",
    "\n",
    "domain = TickTackToeDomain(is_first_player=IS_FIRST_PLAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Global Item for Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_performance_logger():\n",
    "    callback = TickTackToePerformanceLogger()\n",
    "    callback.set_performance_test_interval(TEST_INTERVAL)\n",
    "    callback.set_is_first_player(IS_FIRST_PLAYER)\n",
    "    callback.set_test_game_count(TEST_GAME_COUNT)\n",
    "    return callback\n",
    "\n",
    "def run_performance_test(rl_algo, epsilon, test_length):\n",
    "    watch_iteration = WatchIterationCount(target_count=test_length, log_interval=LOG_INTERVAL)\n",
    "    finish_rules = [watch_iteration]\n",
    "    value_func = TickTackToeKerasValueFunction()\n",
    "    value_func.setUp()\n",
    "    policy = EpsilonGreedyPolicy(domain, value_func, eps=epsilon)\n",
    "    callback = gen_performance_logger()\n",
    "    rl_algo.set_gpi_callback(callback)\n",
    "    rl_algo.GPI(domain, policy, value_func, finish_rules)\n",
    "    return callback.game_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_test_result(title, performance_test_result):\n",
    "    labels = [TEST_INTERVAL * (i+1) for i in range(len(performance_test_result))]\n",
    "    lose_log, draw_log, win_log = [[log[1][i] for log in performance_test_result] for i in range(3)]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(labels, lose_log, label=\"lose rate\")\n",
    "    plt.plot(labels, draw_log, label=\"draw rate\")\n",
    "    plt.plot(labels, win_log, label=\"win rate\")\n",
    "\n",
    "    plt.xlabel(\"GPI iteration\")\n",
    "    plt.ylabel(\"rate(%)\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc = 1)\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACTION_NAME_MAP = {\n",
    "    1 : \"lower_right\",\n",
    "    2 : \"lower_center\",\n",
    "    4 : \"lower_left\",\n",
    "    8 : \"middle_right\",\n",
    "    16: \"middle_center\",\n",
    "    32: \"middle_left\",\n",
    "    64: \"upper_right\",\n",
    "    128: \"upper_center\",\n",
    "    256: \"upper_left\"\n",
    "}\n",
    "\n",
    "def gen_test_case():\n",
    "    bin2i = lambda b: int(b, 2)\n",
    "    \n",
    "    \"\"\"\n",
    "    - - -\n",
    "    - - -\n",
    "    - - -\n",
    "    \"\"\"\n",
    "    first_player_board = bin2i(\"000000000\")\n",
    "    second_player_board = bin2i(\"000000000\")\n",
    "    case1 = (first_player_board, second_player_board)\n",
    "    answer1 = {\n",
    "        'upper_right': 0, 'lower_left': 0, 'upper_left': 0, 'lower_right': 0, 'lower_center': 0,\n",
    "        'middle_right': 0, 'middle_left': 0, 'upper_center': 0, 'middle_center': 0\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    O O -\n",
    "    - - -\n",
    "    - X X\n",
    "    \"\"\"\n",
    "    first_player_board = bin2i(\"110000000\")\n",
    "    second_player_board = bin2i(\"000000011\")\n",
    "    case2 = (first_player_board, second_player_board)\n",
    "    answer2 = {'middle_right': -1, 'upper_right': 1, 'middle_left': -1, 'lower_left': 1, 'middle_center': -1}\n",
    "    \n",
    "    \"\"\"\n",
    "    - - O\n",
    "    - - X\n",
    "    - - -\n",
    "    \"\"\"\n",
    "    first_player_board = bin2i(\"0000010000\")\n",
    "    second_player_board = bin2i(\"000001000\")\n",
    "    case3 = (first_player_board, second_player_board)\n",
    "    answer3 = {'upper_right': 1, 'lower_left': 1, 'upper_left': 1, 'lower_right': 1, 'lower_center': 1, 'middle_left': 0, 'upper_center': 1}\n",
    "    \n",
    "    \"\"\"\n",
    "    - - -\n",
    "    - 0 X\n",
    "    - - -\n",
    "    \"\"\"\n",
    "    first_player_board = bin2i(\"010000000\")\n",
    "    second_player_board = bin2i(\"000001000\")\n",
    "    case4 = (first_player_board, second_player_board)\n",
    "    answer4 = {'upper_right': 1, 'lower_left': 0, 'upper_left': -1, 'lower_right': 0, 'lower_center': -1, 'middle_left': 0, 'middle_center': 1}\n",
    "    \n",
    "    \"\"\"\n",
    "    - O -\n",
    "    - - X\n",
    "    - - -\n",
    "    \"\"\"\n",
    "    first_player_board = bin2i(\"001000000\")\n",
    "    second_player_board = bin2i(\"000001000\")\n",
    "    case5 = (first_player_board, second_player_board)\n",
    "    answer5 = {'lower_left': 0, 'upper_left': 1, 'lower_right': 0, 'lower_center': 0, 'middle_left': 0, 'upper_center': 1, 'middle_center': 1}\n",
    "    \n",
    "    return zip([case1, case2, case3, case4, case5], [answer1, answer2, answer3, answer4, answer5])\n",
    "\n",
    "def visualize_policy(model_weights_path):\n",
    "    domain = TickTackToeDomain()\n",
    "    value_func = TickTackToeKerasValueFunction()\n",
    "    value_func.setUp()\n",
    "    value_func.load_model_weights(model_weights_path)\n",
    "    for state, answer in gen_test_case():\n",
    "        print TickTackToeHelper.visualize_board(state)\n",
    "        actions = [ACTION_NAME_MAP[action] for action in domain.generate_possible_actions(state)]\n",
    "        values = [value_func.calculate_value(state, action) for action in domain.generate_possible_actions(state)]\n",
    "        policy = {action:value for action, value in zip(actions, values)}\n",
    "        print \"answer => %s\" % sorted(answer.items(), key=lambda item: item[1])[::-1]\n",
    "        print \"policy => %s\" % sorted(policy.items(), key=lambda item: item[1])[::-1]\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_LENGTH = 100000\n",
    "TEST_INTERVAL = 1000\n",
    "EPSILON = 0.3\n",
    "performance_test_result = run_performance_test(Sarsa(alpha=0.1, gamma=0.7), epsilon=EPSILON, test_length=TEST_LENGTH)\n",
    "visualize_test_result(\"Sarsa\", performance_test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./resource/ticktacktoe_dqn_test_result.png\" width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ">>> visualize_policy(...)\n",
    "- - -\n",
    "- - -\n",
    "- - -\n",
    "answer => [('lower_center', 0), ('middle_center', 0), ('lower_right', 0), ('upper_left', 0), ('upper_center', 0), ('lower_left', 0), ('middle_left', 0), ('middle_right', 0), ('upper_right', 0)]\n",
    "policy => [('middle_center', 1.2109103), ('upper_right', 1.1978537), ('middle_left', 1.1894823), ('lower_left', 1.1749967), ('upper_center', 1.167393), ('middle_right', 1.1293638), ('upper_left', 1.1246151), ('lower_right', 1.0449142), ('lower_center', 1.0008714)]\n",
    "\n",
    "O O -\n",
    "- - -\n",
    "- X X\n",
    "answer => [('lower_left', 1), ('upper_right', 1), ('middle_center', -1), ('middle_left', -1), ('middle_right', -1)]\n",
    "policy => [('upper_right', 0.67279053), ('middle_left', 0.64982247), ('lower_left', 0.6463871), ('middle_center', 0.64121544), ('middle_right', 0.60430062)]\n",
    "\n",
    "- - -\n",
    "- O X\n",
    "- - -\n",
    "answer => [('upper_center', 1), ('lower_center', 1), ('lower_right', 1), ('upper_left', 1), ('lower_left', 1), ('upper_right', 1), ('middle_left', 0)]\n",
    "policy => [('upper_right', 1.2202574), ('middle_left', 1.1972895), ('lower_left', 1.193854), ('upper_center', 1.1228595), ('upper_left', 1.0800816), ('lower_center', 1.0232753), ('lower_right', 1.0159355)]\n",
    "\n",
    "- O -\n",
    "- - X\n",
    "- - -\n",
    "answer => [('middle_center', 1), ('upper_right', 1), ('middle_left', 0), ('lower_right', 0), ('lower_left', 0), ('lower_center', -1), ('upper_left', -1)]\n",
    "policy => [('middle_center', 1.1228595), ('middle_left', 1.1014315), ('lower_left', 1.0869459), ('upper_right', 1.0510076), ('upper_left', 1.0365642), ('lower_right', 0.9568634), ('lower_center', 0.85402536)]\n",
    "\n",
    "- - O\n",
    "- - X\n",
    "- - -\n",
    "answer => [('middle_center', 1), ('upper_center', 1), ('upper_left', 1), ('middle_left', 0), ('lower_center', 0), ('lower_right', 0), ('lower_left', 0)]\n",
    "policy => [('middle_left', 1.2288644), ('lower_left', 1.2254292), ('middle_center', 1.2202574), ('lower_center', 1.0548503), ('upper_center', 1.0510076), ('lower_right', 1.0475106), ('upper_left', 0.96497869)]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
